{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12aef1c",
   "metadata": {},
   "source": [
    "# Python Week 4: NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fec61",
   "metadata": {},
   "source": [
    "For this week we will be doing a deep dive into Pandas and NumPy. These two libraries are probably within the top-five most used python libraries, and for good reason; they provide fast, reliable, and easy to read classes and methods for the purpose of numerical computing, data analysis, and machine learning. For today we will be looking at some of their more complex features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like always we start by importing the necessary libraries\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82239165",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a testing array for the lesson, 10x10 normally distributed\n",
    "test_array = random.randn(10,10)\n",
    "print(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f063710",
   "metadata": {},
   "source": [
    "### Review and Common Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c28c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review from week two\n",
    "# remember that if we want to index into a NumPy array, we need at least as many indices as dimensions\n",
    "# also, NumPy uses row, xolumn indexing like in Linear Algebra\n",
    "\n",
    "print(test_array[1][1]) # second row, second column\n",
    "print(test_array[-1][-1]) # we can also negative index to index from the end of the array\n",
    "print(test_array[-1,-1]) # we can use a single bracket as well\n",
    "# a new variant on this however is fancy indexing, where we can pass an array of indices\n",
    "rows = [1,2,3]\n",
    "cols = [9,8,7]\n",
    "print(test_array[rows,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d04c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy accesses the same object when we index thus a statement like:\n",
    "test_array[-1,-1] = -5\n",
    "# changes the actual array\n",
    "test_array[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should also review slicing\n",
    "# if indexing is like a specific coordinate, slicing is like grabbing a specific line of latitude or longitude\n",
    "# remember, : means all\n",
    "\n",
    "print(test_array[0,:]) # grab all columns in first row\n",
    "print(test_array[:,0]) # grab all rows in first column\n",
    "print(test_array[:5]) # grab all rows until row 5\n",
    "print(test_array[5:]) # grab all rows from 5 till end\n",
    "print(test_array[0,5:]) # grab last 5 entries in first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ff37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are some common methods of NumPy you should be able to know how to use\n",
    "# we can use size to determine the number of entries\n",
    "print(test_array.size)\n",
    "\n",
    "# we can use shape to determine the dimensions\n",
    "print(test_array.shape)\n",
    "\n",
    "# we can use ndim to determine, well, the number of dimensions\n",
    "print(test_array.ndim)\n",
    "\n",
    "# we can also check the datatype\n",
    "print(test_array.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more useful methods/functions\n",
    "# we can transpose an array \n",
    "print(test_array.transpose())\n",
    "\n",
    "# we can sort our arrays\n",
    "print(np.sort(test_array))\n",
    "\n",
    "# we can sort the array by its indices\n",
    "print(np.argsort(test_array))\n",
    "\n",
    "\n",
    "# in place sorting, permanantly changes the order of the array, so beware!\n",
    "test_array.sort() \n",
    "test_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffaea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should also look at splitting and concatenating arrays\n",
    "# create a new test array\n",
    "test_array1 = random.randn(2,2)\n",
    "test_array2 = random.randn(2,2)\n",
    "\n",
    "# lets say we need to combine two arrays\n",
    "test_array_1_2 = np.concatenate([test_array1, test_array2]) # note that in this case, this is ambiguous\n",
    "print(test_array_1_2)\n",
    "# in my opinion hstack and vstack are better because you always get the proper behavior\n",
    "# stack horizontally\n",
    "test_array_1_2_h = np.hstack([test_array1, test_array2])\n",
    "print(test_array_1_2_h)\n",
    "#stack vertically\n",
    "test_array_1_2_v = np.vstack([test_array1, test_array2])\n",
    "print(test_array_1_2_v)\n",
    "\n",
    "# notice that concatenate produces the same result as vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting is the inverse operation\n",
    "# biblically inspired programmer humour\n",
    "the_red_sea = random.randn(10,10)\n",
    "\n",
    "the_red_sea_l, the_red_sea_r = np.split(the_red_sea, 2) # default splits vertically\n",
    "print(the_red_sea_l)\n",
    "\n",
    "# fruit inspired humour\n",
    "\n",
    "banana = random.randn(10,10)\n",
    "\n",
    "left_banana, right_banana = np.vsplit(banana, 2)\n",
    "print(left_banana)\n",
    "\n",
    "top_banana, bottom_banana = np.hsplit(banana, 2)\n",
    "print(top_banana)\n",
    "\n",
    "# we can also split arrays at specific points in an array\n",
    "# all out of bad jokes\n",
    "\n",
    "my_array = random.randn(10,10)\n",
    "w, x, y  = np.split(my_array,[3,6]) #split at third row, and sixth column\n",
    "print(w,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ad1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we should now talk about universal functions, we use these when we want to apply operations element wise in numpy\n",
    "# we are probably aware of them as when you use the arithmetic operations in numpy, you actually are calling a\n",
    "# a wrapper for those functions\n",
    "# for example:\n",
    "test_array3 = random.randn(10,10)\n",
    "test_array + test_array3 == np.add(test_array3, test_array)\n",
    "\n",
    "# this persists for other arithmetic operations in python and is thus trivial to describe, consult documentation if\n",
    "# you need help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps something more useful is numpy where\n",
    "# where lets you check conditions where something is true or not and checks it in a bitwise fashion i.e. every\n",
    "# element, but its much faster than a for loop, and it allows us to change that original array\n",
    "\n",
    "# lets create an imaginary situation where we need to run a t-test on some imaginary pearson correlations\n",
    "\n",
    "# lets create a supposed matrix of correlation coefficients\n",
    "corr = random.rand(10,10)\n",
    "# now lets create a supposed array that contains the p-value of those coefficients\n",
    "ps =  abs(random.normal(0.05, 0.5, [10,10]))\n",
    "\n",
    "# first let's eliminate all correlations that are not significant\n",
    "# basically, find all values in ps where the entry is greater than 0.05, find that same location in corr,\n",
    "# replace with zero\n",
    "sig_corr = np.where(ps > 0.05, corr, 0)\n",
    "print(sig_corr)\n",
    "# another similar operation is extract, which grabs values based on boolean logic\n",
    "sig_corr1 = np.extract(ps <= 0.05, ps)\n",
    "print(sig_corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another very useful thing is the ability to write our own vectorized functions in python, this will always be\n",
    "# faster than a for loop, but almost never faster than a vector function written in C/C++ so be wary\n",
    "\n",
    "# lets create a funciton here\n",
    "def my_func(a, b):\n",
    "    if a is not b:\n",
    "        return a\n",
    "    else:\n",
    "        return b**3 + a\n",
    "\n",
    "# we can then call the vector class in numpy\n",
    "vectorized_func = np.vectorize(my_func)\n",
    "# we can now run our newly vectorized function, obviosuly for a case like this, we are probably going overkill\n",
    "# but you can use your imagination\n",
    "# also for the adventurous, you can make your own vectorized functions in C/C++ and port them to python\n",
    "# that's however outside the scope of these lessons\n",
    "vectorized_func(np.array([1,2,3,4]),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82326819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy also has an excellent convolve fucntion, for when we need to combine two functions like during signal\n",
    "# processing\n",
    "plt.style.use('ggplot')\n",
    "# let's define a time axis\n",
    "time = np.linspace(0, 60, 60)\n",
    "response = random.randn(60)\n",
    "\n",
    "# lets define a kernel\n",
    "kernel_size = 5\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(time, response, color='blue')\n",
    "ax.plot(time, convolve_r, color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90596584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you also have no excuse for not knowing where to find documentation with numpy lookfor\n",
    "# numpy comes with a literal search function!\n",
    "np.lookfor('discrete fourier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f4148",
   "metadata": {},
   "source": [
    "In all honesty, this is just scratching the surface of NumPy. There is so many applications for signal processing, linear algebra, etc. that I couldn't possibly show you everything you need to know. If you have a specific use case thats numerically oriented however, I would always suggest to look whether NumPy has a solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0745f",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d1faf1",
   "metadata": {},
   "source": [
    "As a quick note, many of the functions in Pandas has cognates in NumPy, so I'm not going to waste time going over them, if you need to concatenate or split DF's, please consult the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e151df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import this test dataset from Kaggle that I downloaded\n",
    "# it has relative protein expression of several proteins in mice that are either WT or down-syndrome modeled,\n",
    "# whether they received a pharmacologicla agent, and whehter they were fear conditioned or not\n",
    "\n",
    "mouse_protein = pd.read_csv('Data_Cortex_Nuclear.csv')\n",
    "print(mouse_protein.head()) # print first 5 rows\n",
    "print(mouse_protein.tail()) # print last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f31ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a quick look at all of the columns, their datatypes, and general characteristics\n",
    "print(mouse_protein.columns)\n",
    "print(mouse_protein.dtypes)\n",
    "print(mouse_protein.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so I won't talk about concatenation as like i stated this is simialr ot NumPy methods, the one advantage about\n",
    "# Pandas however is that it is intelligent in how it parses the column and row labels, meaning you can easily \n",
    "# concatenate multiple spreadsheets with the same index labels into one large document\n",
    "\n",
    "# but we can talk about the merge feature\n",
    "# let's say you have new data that you want to add to an existing DF\n",
    "# for example, lets say we measured one last protein\n",
    "\n",
    "BDNF = pd.DataFrame({'BDNF':random.rand(1080),'MouseID':mouse_protein.MouseID})\n",
    "BDNF\n",
    "mouse_protein = mouse_protein.merge(BDNF, how='inner')\n",
    "mouse_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f11fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to explain how this is different from concatenating\n",
    "# create different dataframes\n",
    "df1 = pd.DataFrame({'Key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df2 = pd.DataFrame({'Key': ['a', 'b', 'd'], 'data2': range(3)})\n",
    "\n",
    "print(pd.merge(df1, df2))\n",
    "print(pd.concat([df1, df2]))\n",
    "\n",
    "# be wary how you use these as they seem similar, but are not always identical and can have different meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another advantage of pandas is its ability to easily aggregate data\n",
    "# lets take a look at some of those methods\n",
    "\n",
    "# one way is groupby, which allows us to basically group some labels, apply a function, then get a summary\n",
    "# let's say i want the mean value for each distinct group in this experiment\n",
    "print(mouse_protein.groupby(['Treatment', 'Genotype', 'Behavior'], as_index=False).mean())\n",
    "\n",
    "# another option is a pivot table, I tend to find this less useful, but it does perform a function\n",
    "# as you probably noticed this does the same calculation\n",
    "print(pd.pivot_table(mouse_protein, index=['Treatment','Genotype'], columns=['Behavior'],aggfunc=np.mean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46aa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the real advantages of pandas however is method chaining\n",
    "# method chaining is the application of mulitple operations that can be condensed into a single line\n",
    "# in this single line I was able to find \n",
    "print(mouse_protein[mouse_protein.Behavior.eq('C/S')].agg({'SYP_N': [\"mean\", \"median\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas also has a lot of plotting features to make quick plots of descriptive statistics\n",
    "# as a note these aren't intended for publication\n",
    "pd.plotting.boxplot(mouse_protein)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b8e98",
   "metadata": {},
   "source": [
    "As a final note, this isn't a end all be all guide. I tried to include the most useful tools for you all that would be generalizable to many applications. Some of these examples don't even paint the full picture of that specific funciton or method, so I beleive it is imperative that you familiarize yourselves with the documentation of Pandas and NumPy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
