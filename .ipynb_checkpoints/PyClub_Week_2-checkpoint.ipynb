{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9e2c3e",
   "metadata": {},
   "source": [
    "# Python Week 2: Numerical Computation and Vectorized Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573d4ba",
   "metadata": {},
   "source": [
    "As scientists, a disproportionate amount of our coding will involve numerical operations and computations. Python's built in data-structures, while serving their own purposes, are not meant to handle the large datasets of most scientists. For this reason we need to turn to two similar but distinct libraries: NumPy and Pandas. These libraries will feel very simialr to the types of datastructures inherent to programming languages like Matlab and R. This is the reason why I tend to favor Python as a language; anything you can do in another language, it can do and better (not always the case but in many cases this can be true).\n",
    "\n",
    "The last half of this lesson will focus on vectorized operations and optimization lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0da2de",
   "metadata": {},
   "source": [
    "To start lets examine NumPy, its main contribution is the class \"ndarray\" (N-dimensional array). This is more commonly referred to as a matrix in mathematical circles. With NumPy we are restricted to numerical data, lets see what it can do below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets call the ndarray constructor inherent to NumPy, remember from our last lesson that an ndarray is a\n",
    "# class, or object, and when we call this class we are creating an instance\n",
    "# from NumPy's documentation: numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)\n",
    "\n",
    "empty_array = np.array([])# this array is completely empty, and has no dimensions specified\n",
    "print(empty_array)\n",
    "# lets create a 2x2 array now, notice how me make a nested list when hard-coding this array\n",
    "two_by_two = np.array([[1,2],[3,4]])\n",
    "print(two_by_two)\n",
    "\n",
    "type(two_by_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2016a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also call stereotyped array constructors that have specific shapes and sizes, this can be useful for \n",
    "# pre-allocating memory or when we have a base value so to speak\n",
    "\n",
    "print(np.empty([2,2]))\n",
    "print(np.ones([2,2]))\n",
    "print(np.zeros([2,2]))\n",
    "print(np.arange(0,100,2.50)) # note Numpy calcualtes this with a half open interval i.e. [0, 100)\n",
    "print(np.linspace(0,100,num=27))\n",
    "\n",
    "# a note about np.empty(): this array isn't actually populated with zero's, its actually populated with \"pointers\"\n",
    "# or basically coordinates in your memory to random values, do not use np.empty() thinking it'll have the same\n",
    "# functionality as np.zeros(), you will make computational errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in some cases we need a collection of random (ok so random numbers in computing are actually determinsitic\n",
    "# and we can reliably guess their values based on how they are algorithmically generated, thus we can more properly\n",
    "# call these pseudorandom, for true random numbers we need to take values from true randomly governed events like\n",
    "# position data on your trackpad. . .) numbers\n",
    "\n",
    "# in some cases developers leave out specific modules in the broad import statmentsa nd you'll need an accesory\n",
    "# import statement\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "# lets create an array (row vector) of normally distributed numbers\n",
    "normal_array = random.randn(2000)\n",
    "# uniformly distibuted numbers 0-1\n",
    "uniform_array = random.rand(1000)\n",
    "# pseudorandom integers\n",
    "int_array = random.randint(2000, size=(100,1))\n",
    "# plot a new array by my random keystrokes of int from 0-9\n",
    "ryan_array = np.array([1,6,2,5,7,3,7,4,1,7,9,6,1,8,3,6,9,4,2,6,8,4,2,5,6,8,9,0,8,5,3,2,2,3,5,6,7,8,9,0,6,5,6,8,5,4,1,2,5,3,0,5,3,6,2,4,7,0,7,2,4,7,9,3,5,6,8,4,5,7,4,])\n",
    "\n",
    "# plot the relative distributions of each as proof of their \"randomness\"\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,7))\n",
    "axs[0].hist(normal_array)\n",
    "axs[1].hist(uniform_array)\n",
    "axs[2].hist(int_array)\n",
    "axs[3].hist(ryan_array)\n",
    "\n",
    "# numpy has a lot of different ways to draw numbers from specific distributions like poisson, gamma, etc. this is\n",
    "# just a few of the msot common ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67117b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and slicy in numpy is fairly simple, as a note however, when you index or slioce an array, you are not\n",
    "# creating a virutal copy i.e. you are referencing the exact spot in memory that those values habitate\n",
    "\n",
    "##indexing\n",
    "\n",
    "# lets create a random array \n",
    "random_array = random.randn(10,10)\n",
    "\n",
    "#a single index will index to the relevant row (remember, NumPy uses [row, column] indices)\n",
    "print(random_array[1])\n",
    "\n",
    "# NumPy supports double indexing, so array[m][n] == array[m,n]\n",
    "print(random_array[1][2] == random_array[1,2])\n",
    "print(random_array[1][2])\n",
    "\n",
    "# numpy can index >2 dimensional arrays as well (though i would use a class here to make this simpler)\n",
    "multi_dim_array = np.array([random_array, random_array, random_array])\n",
    "print(multi_dim_array[2,3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713acf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##slicing##\n",
    "\n",
    "# the colon means \"all\" and can be used to slice\n",
    "print(random_array[1,:]) # grab all column values in the first row\n",
    "print(random_array[5:]) # grab fifth index to end of array\n",
    "print(random_array[:5, :2])# grab until the fifth index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b33dfc",
   "metadata": {},
   "source": [
    "Now lets take a look at the basics of Pandas. Similar ot NumPy, its main claim to fame is adding a new data\n",
    "structure: the dataframe. As you'll notice however, there is some key differences that set these two libraries apart. Most obviously, Pandas can incorporate non-numerical data, and can even have both numerical and non-numerical entries within the same dataframe. Why is this important? Because I suspect all of us has a collection of spreadsheets that has both numerical and non numerical properties that we would love to be able to manipulate. This is the priamry fucntion of Pandas, to make data wrangling easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53692064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets see how we can construct pandas DF's similar to numpy:\n",
    "\n",
    "# empty df\n",
    "empty_df = pd.DataFrame()\n",
    "\n",
    "# from a dictionary\n",
    "my_dataset = {\n",
    "  'PI': [\"Steve\", \"Mark\", \"Ben\"],\n",
    "  'number': [13, 27, 12]\n",
    "}\n",
    "\n",
    "my_df = pd.DataFrame(my_dataset)\n",
    "\n",
    "# from a numpy array\n",
    "two_by_two = np.array([[1,2],[3,4]])\n",
    "two_by_two = pd.DataFrame(two_by_two)\n",
    "\n",
    "# from a csv\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "\n",
    "print(empty_df)\n",
    "print(my_df)\n",
    "print(two_by_two)\n",
    "print(iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3416c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# indexing in pandas is somewhat similar to NumPy but remember from last week that it uses column x row indices\n",
    "\n",
    "# numerical indexing\n",
    "two_by_two = pd.DataFrame([[1,2],[3,4]])\n",
    "print(two_by_two[1][0]) # index second column, first row\n",
    "# pandas does not accept this format two_by_two[1,1]\n",
    "\n",
    "# index by column \n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "print(iris['sepal_length']) \n",
    "\n",
    "print(iris.sepal_length == iris['sepal_length'])\n",
    "\n",
    "# access specific entries in a column\n",
    "print(iris['sepal_length'][5])\n",
    "\n",
    "# slicing by ranges (identical to NumPy), when you slice this way pandas slices by row x column\n",
    "print(iris[:5])\n",
    "print(iris[100:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has incredibly powerful ways where we can index based \n",
    "\n",
    "# lets look at boolean based indexing \n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "v = iris[iris['species'] == 'virginica']\n",
    "swv = v[v['sepal_width'] > 3.7]\n",
    "print(swv)\n",
    "\n",
    "# we can also index based on what our index labels are equivalent to, lets look at a different dataset now\n",
    "# for this we need the .loc method, as a note we are given a series or new dataframe when we do this i.e. we\n",
    "# are not accessing the same memory space and are in essence creating a new object\n",
    "# also not, when we use a number as an index in .loc that treats it as a label, not an index!\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv').transpose()\n",
    "print(tips.loc['total_bill'])\n",
    "print(tips.loc[['total_bill','tip']])\n",
    "print(tips.loc['total_bill'] > 12.76)\n",
    "\n",
    "# we can also index numerically in pandas when we want to ignore the labels, this does row indexing!\n",
    "print(tips.iloc[1])\n",
    "print(tips.iloc[[1,2,3]])\n",
    "print(tips.iloc[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e2ade",
   "metadata": {},
   "source": [
    "To finish off today we are going to talk about vector operations and optimization of code. Remember, python is interpreted thus it is inherently slower than compiled languages, but we can use certain practices to speed up our code. To start lets look at the differences between NumPy and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "np_array = random.randn(20,20)\n",
    "pd_array = pd.DataFrame(np_array)\n",
    "\n",
    "# time how long it takes to calculate the mean of a NumPy array\n",
    "start_time = time.time()\n",
    "\n",
    "np.mean(np_array)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "np_ti = end_time - start_time\n",
    "\n",
    "# time how long it takes to calculate the speed of a Pandas DataFrame\n",
    "start_time1 = time.time()\n",
    "\n",
    "pd_array.mean()\n",
    "\n",
    "end_time1 = time.time()\n",
    "\n",
    "pd_ti = end_time1 - start_time1\n",
    "\n",
    "print(f'It took Numpy {np_ti} second(s) to run, and Pandas {pd_ti} second(s) to run, or NumPy was {pd_ti / np_ti}x faster!')\n",
    "\n",
    "# so obviosuly these two operations are both incredibly fast, but note that NumPy is faster for numerical operations,\n",
    "# also note that this relationship is not linear! Thus try to perform numerical operations in NumPy when possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized operatiosn should always be used as they will 99.999999% of the time be faster than for-loop operations\n",
    "# this is because modern computing hardware is designed to perform these types of calcualtions with ease\n",
    "# if you're coming from matlab and R these are the main operations by which these languages operate\n",
    "# this occurs because in for loops you apply a fucntion over each and every entry, but in vectorized operations \n",
    "# you apply a fucntion once, and they are written in C/C++ generally\n",
    "start_time = time.time()\n",
    "np.sum(np.arange(100000))\n",
    "end_time = time.time()\n",
    "vector_time = end_time - start_time\n",
    "\n",
    "start_time1 = time.time()\n",
    "total = 0\n",
    "for i in np.arange(100000):\n",
    "    total = i + total\n",
    "end_time1 = time.time()\n",
    "for_time = end_time1 - start_time1\n",
    "\n",
    "print(f'Vector operations are {for_time / vector_time}x faster!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look at how vectorized operations in Pandas are better\n",
    "myDF = pd.DataFrame(random.randn(1000))\n",
    "\n",
    "# pd.apply() applies a function iteratively row or column wise across a pandas object\n",
    "start_time = time.time()\n",
    "myDF.apply(lambda x: x**2)\n",
    "end_time = time.time()\n",
    "apply_time = end_time - start_time\n",
    "\n",
    "start_time1 = time.time()\n",
    "myDF**2\n",
    "end_time1 = time.time()\n",
    "\n",
    "vector_time = end_time1 - start_time1\n",
    "\n",
    "print(f'Vector operations are {apply_time / vector_time}x faster!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2550e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
